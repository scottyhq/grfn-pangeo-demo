{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pangeo demo: Getting Ready for NiSAR (GRFN)\n",
    "\n",
    "This notebook demonstrates advanced analysis of GRFN InSAR data using Pangeo cloud-based software.\n",
    "\n",
    "The images total 25Gb: over 200 unwrapped phase interferograms with 30x30m posting\n",
    "\n",
    "In particular, we'll explore data exploration and analysis with Python tools. **The computation is running on the Google Cloud next to the data** \n",
    "\n",
    "To run each code cell, use 'shift+enter'\n",
    "\n",
    "**Warning!** you can modify this notebook, upload files, and save files listed on the left (right-click and you will see a download option). BUT!... it is an ephemeral demo. Work will be lost if you leave this idle for a bit. Everything shuts down automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "import gcsfs\n",
    "import intake\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os.path\n",
    "from dask_kubernetes import KubeCluster\n",
    "from dask.distributed import Client\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch a Kubernetes Cluster\n",
    "\n",
    "we can use a kubernetes cluster to increase our computational resources\n",
    "\n",
    "2 workers are selected by default, and 2 more will be launched if necessary with adaptive scaling. It may take a few minutes for the machines to become active.\n",
    "\n",
    "You can see the cluster activity with the dask labextension (click the dashboard url link to open a new browser tab, or paste the link into the dask lab-extension (winged icon on the left)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = KubeCluster(n_workers=2)\n",
    "cluster.adapt(maximum=4)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List files on Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've converted GRFN interferograms to cloud-optimized geotiffs\n",
    "# And made them available in a public cloud bucket\n",
    "bucket = 'grfn-hawaii-124-cog'\n",
    "\n",
    "# This creates a virtual local file listing\n",
    "fs = gcsfs.GCSFileSystem(project='pangeo-181919')\n",
    "images = fs.ls(f'pangeo-data/{bucket}')\n",
    "\n",
    "print('Number of images:', len(images))\n",
    "print('First image:', images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each of these images has an associates public URL:\n",
    "# We'll use pandas to make a sorted dataframe of all the images\n",
    "def parse_name(gsPath, key='date1'):\n",
    "    ''' grab project, bucket, date1, date2, format from file name, return dictionary'''\n",
    "    pattern = '{project}/{bucket}/{date1:%Y%m%d}-{date2:%Y%m%d}-{format}'\n",
    "    parsed = intake.source.utils.reverse_format(pattern, gsPath)\n",
    "    val = parsed[key]\n",
    "    return val\n",
    "\n",
    "def make_dataframe(images):\n",
    "    ''' organize pandas dataframe by parsing filename'''\n",
    "    df = pd.DataFrame(dict(gs=images))\n",
    "    df = df.sort_values('gs').reset_index(drop=True)\n",
    "    df['url'] = 'http://storage.googleapis.com/' + df.gs.str[:]\n",
    "    df['date1'] = df.gs.apply(parse_name, args=('date1',))\n",
    "    df['date2'] = df.gs.apply(parse_name, args=('date2',))\n",
    "    df['dt'] = df.date1 - df.date2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = make_dataframe(images)\n",
    "print('Total images:', len(df))\n",
    "print('First date:', df.date2.iloc[0])\n",
    "print('Last date:', df.date1.iloc[-1])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Cloud-optimized geotiffs (COGs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rasterio uses the gdal vsicurl system to access files\n",
    "# on a cloud server\n",
    "env = rasterio.Env(GDAL_DISABLE_READDIR_ON_OPEN='EMPTY_DIR',\n",
    "                  CPL_VSIL_CURL_USE_HEAD=False,\n",
    "                  CPL_VSIL_CURL_ALLOWED_EXTENSIONS='TIF',\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the first file in the set of images into xarray DataArray (w/ dask)\n",
    "# note this is very fast b/c only metadata is downloaded to local memory\n",
    "# chunks are based on cloud-optimized geotiff internal tiling\n",
    "xchunk = 512\n",
    "ychunk = 512\n",
    "with env:\n",
    "    da = xr.open_rasterio(df.url[0], parse_coordinates=True, chunks={'band': 1, 'x': xchunk, 'y': ychunk})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an xarray DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since all these images are pre-aligned ('analysis ready')\n",
    "# we get best performance loading w/o metadata & coordinate checking\n",
    "def create_dataset(df, chunks={'band': 1, 'x': 5120, 'y': 512}):\n",
    "    # Note: this takes a minute b/c coordinate alignment is checked\n",
    "    from ipywidgets import IntProgress\n",
    "    from IPython.display import display\n",
    "    probar = IntProgress(value=0, min=0, max=len(df), step=1, \n",
    "                         description='Loading:')\n",
    "    display(probar)\n",
    "    #print(rasterio.env.getenv())\n",
    "    datasets = []\n",
    "    # Create dataset to fill based on first image\n",
    "    da = xr.open_rasterio(df.url[0], \n",
    "                          parse_coordinates=True, \n",
    "                          chunks=chunks) \n",
    "    probar.value += 1\n",
    "    datasets.append(da.to_dataset(name='unw'))\n",
    "    \n",
    "    # Loop over remaining images to fill array\n",
    "    for i,row in df[1:].iterrows():\n",
    "        probar.value += 1\n",
    "        url = row.url\n",
    "        \n",
    "        da = xr.open_rasterio(url, parse_coordinates=False, chunks=chunks)\n",
    "        datasets.append(da.to_dataset(name='unw'))\n",
    "    \n",
    "    ds = xr.concat(datasets, dim='band')\n",
    "    ds.coords['band'] = np.arange(len(df))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with env:\n",
    "    DS = create_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset size (Gb): ', DS.nbytes/1e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a coastline water mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a coastline mask to the dataset\n",
    "# Land water mask (WGS84latlon epsg:4326)\n",
    "gf = gpd.read_file(\"hawaii-gshhs.geojson\")\n",
    "gf.geometry.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE shapefle rasterization and projection from WGS84 to UTM\n",
    "with rasterio.open(df.url.iloc[0]) as src:\n",
    "    projected = gf.to_crs(src.crs)\n",
    "    out_image, out_transform = mask(src, projected.geometry.values, indexes=1)\n",
    "    \n",
    "water = (out_image == 0)\n",
    "DS.coords['mask'] = (('y', 'x'), water)\n",
    "DSmasked = DS.where(DS.mask == False).chunk(chunks={'band': 1, 'x': 5120, 'y': 512})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSmasked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive visualization with holoviews\n",
    "\n",
    "**NOTE:** you may need to resize this pane to see all the buttons (drag grey separator bar to the right)\n",
    "\n",
    "* Once in an xarray DataSet, hvplot can easily display images interactively:\n",
    "* Note column of buttons on upper right side of figure.\n",
    "* In addition to buttons, there is a time slider for band selection\n",
    "    * click slider button and use arrow keys for fine control\n",
    "* Box zoom button updates displayed resolution on the fly\n",
    "* Moving cursor over image gives coordinates and unwrapped phase value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = DSmasked.hvplot.image(x='x',y='y',groupby='band', dynamic=True, rasterize=True,\n",
    "                      width=700, height=500, cmap='magma')\n",
    "\n",
    "limits = hv.streams.RangeXY(source=img)\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save current view / subset\n",
    "\n",
    "We can save a local copy of the current image with a function.\n",
    "\n",
    "* select band=1 in interactive image browser above\n",
    "    * zoom into volcano deformation zone in south (bright area)\n",
    "        * run 2 cells below to save the local image subset\n",
    "            * a geotiff will appear in the file browser on the left\n",
    "                * right click the file and select 'download to get it on your laptop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_src(img):\n",
    "    ''' get current image displayed '''\n",
    "    image_no = img.callback.args\n",
    "    image_url = df.url.iloc[image_no]\n",
    "\n",
    "    return image_url\n",
    "\n",
    "\n",
    "def get_window(img,src):\n",
    "    ''' get current rasterio window from holoviews plot '''\n",
    "    limits = img.streams[1]\n",
    "    if limits.x_range == None:\n",
    "        bounds = src.bounds\n",
    "    else:\n",
    "        bounds = (limits.x_range[0], limits.y_range[0], limits.x_range[1], limits.y_range[1])\n",
    "    uly,ulx = src.index(bounds[0], bounds[3])\n",
    "    lry,lrx = src.index(bounds[2], bounds[1])\n",
    "\n",
    "    width = lrx - ulx\n",
    "    height = lry - uly\n",
    "\n",
    "    return rasterio.windows.Window(ulx, uly, width, height)\n",
    "\n",
    "def save_current_view(img, name='local-image.tif'):\n",
    "    from ipywidgets import IntProgress\n",
    "    from IPython.display import display\n",
    "    probar = IntProgress(value=0, min=0, max=4, step=1, \n",
    "                         description='Saving:')\n",
    "    display(probar)     \n",
    "    \n",
    "    with env:\n",
    "        image_url = get_src(img)\n",
    "        print(f'Saving {image_url}...')\n",
    "        with rasterio.open(image_url) as src:\n",
    "            probar.value +=1\n",
    "            profile = src.profile.copy()\n",
    "            window = get_window(img, src)\n",
    "            print(window)\n",
    "            win_transform = src.window_transform(window)\n",
    "            probar.value +=1\n",
    "            data = src.read(1, window=window)\n",
    "        \n",
    "        profile.update({\n",
    "                'dtype': 'float32',\n",
    "                'height': data.shape[0],\n",
    "                'width': data.shape[1],\n",
    "                'blockxsize': 256,\n",
    "                'blockysize': 256,\n",
    "                'transform': win_transform})  \n",
    "        probar.value += 1\n",
    "        localname = 'subset-' + os.path.basename(src.name)\n",
    "        with rasterio.open(localname, 'w', **profile) as dst:\n",
    "            dst.write_band(1, data) \n",
    "    probar.value +=1\n",
    "    \n",
    "    return localname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localname = save_current_view(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and plot the saved subset to verify it's the same\n",
    "# Since this is only a single file, we won't load with dask\n",
    "print(localname)\n",
    "with env:\n",
    "    with rasterio.open(localname) as src:\n",
    "        print(src.profile)\n",
    "        da = xr.open_rasterio(src.name)\n",
    "da.hvplot.image('x', 'y', groupby='band', dynamic=True, rasterize=True, \n",
    "          width=700, height=500, cmap='magma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel computations\n",
    "\n",
    "With xarray DataSets, we can do parallel computations on the KubeCluster, using dask behind the scenes. Here is a simple example getting the mean phase value for each interferogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xarray_selection(img, band=False):\n",
    "    ''' get selection dictionary from hvplot'''\n",
    "    selection = {}\n",
    "    selection['x'] = slice(*limits.x_range)\n",
    "    selection['y'] = slice(*limits.y_range[::-1])\n",
    "    if band:\n",
    "        selection['band'] = [img.callback.args[0],]\n",
    "    return selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset chunks after selection for better performance\n",
    "ds = DSmasked.sel(get_xarray_selection(img))\n",
    "ds = ds.chunk(dict(band=213,x=512,y=512))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm we've got the same region\n",
    "#ds.hvplot('x', 'y', groupby='band',dynamic=True, rasterize=True, \n",
    "#          width=700, height=500, cmap='magma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Stack\n",
    "# NOTE: haven't normalized to common reference point, this is just for illustration purposes\n",
    "stack = ds.where(ds.mask == False).mean(dim='band')\n",
    "stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep in distributed cluster memory\n",
    "ds_stack = stack.persist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_stack.unw.plot.imshow(center=False, cmap='magma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all values of pixel at a specfic easting, northing\n",
    "# compute pulls from distributed memory to local RAM\n",
    "xcen = 260000\n",
    "ycen = 2145000\n",
    "ts = ds.sel(x=xcen, y=ycen, method='nearest').compute()\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ts.unw.to_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot this\n",
    "# Holoviews is also great for interative 2D plots\n",
    "\n",
    "#line = s.hvplot(width=700, height=300, legend=False)\n",
    "points = s.hvplot.scatter(width=700, height=300, legend=False)\n",
    "label = f'Unwrapped LOS Phase [rad]: easting={xcen:g} , northing={ycen:g}'\n",
    "\n",
    "#(line * points).relabel(label)\n",
    "points.relabel(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from plot can easily be saved to a CSV\n",
    "#points.data.to_csv()\n",
    "#or\n",
    "s.to_csv('time-series.csv', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This short demo just scratches the surface!\n",
    "\n",
    "The main point is to illustrate computational infrastructure that can be deployed next to data stored on the Cloud. In order to take advange of the interactive scalable visualization and computation, data must be stored in object store (e.g. GCS, S3) as Cloud Optimized Geotiff (COG)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
